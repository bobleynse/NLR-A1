{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    # Input Layer [batch_size, image_height, image_width, channels]\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training and eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_data, train_labels),(eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000279092AD710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up logging for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\midas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\users\\midas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\users\\midas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.10853776 0.10022881 0.09384003 0.10200819 0.09771208 0.1007779\n",
      "  0.09740922 0.09592162 0.10355821 0.10000616]\n",
      " [0.10669454 0.09429123 0.09189931 0.10657214 0.10116133 0.09710133\n",
      "  0.0992991  0.10494359 0.10072822 0.09730913]\n",
      " [0.11872519 0.08837564 0.09215679 0.0981948  0.10817555 0.10524967\n",
      "  0.09086188 0.08966755 0.10987332 0.09871962]\n",
      " [0.10161474 0.08700529 0.10687764 0.09588303 0.10921381 0.0967982\n",
      "  0.09016045 0.10223786 0.09442154 0.11578753]\n",
      " [0.11099111 0.08283233 0.08765381 0.09845312 0.12085769 0.09421743\n",
      "  0.09654889 0.10119232 0.10964238 0.09761099]\n",
      " [0.10612001 0.09108026 0.09243591 0.09704734 0.12690012 0.08210867\n",
      "  0.09601668 0.10348567 0.10179166 0.10301372]\n",
      " [0.10676898 0.08807243 0.09865561 0.09761404 0.11602473 0.10938957\n",
      "  0.0926461  0.08768947 0.10279366 0.1003454 ]\n",
      " [0.1037088  0.09425937 0.10311815 0.10763168 0.12267748 0.09606016\n",
      "  0.10105898 0.08735891 0.10064472 0.08348171]\n",
      " [0.10654542 0.0966545  0.10019675 0.10848787 0.10654338 0.10183369\n",
      "  0.09071207 0.10224146 0.10140498 0.0853799 ]\n",
      " [0.10781651 0.0965767  0.1006809  0.09780878 0.09808544 0.10800031\n",
      "  0.08614495 0.09521543 0.10251334 0.10715771]\n",
      " [0.1172073  0.08460274 0.0996233  0.08718481 0.1287054  0.09459984\n",
      "  0.08428887 0.09101509 0.11348519 0.09928741]\n",
      " [0.10068122 0.08780187 0.10244797 0.10279215 0.10809043 0.1032506\n",
      "  0.0940877  0.09877157 0.10143025 0.10064625]\n",
      " [0.11586358 0.08191101 0.09782525 0.09610002 0.10517572 0.09107281\n",
      "  0.09712528 0.09978034 0.11351326 0.10163274]\n",
      " [0.09955975 0.10060582 0.08602408 0.09921293 0.12223896 0.09178583\n",
      "  0.09772389 0.1038764  0.09862402 0.10034835]\n",
      " [0.10606181 0.0910831  0.09931041 0.09720375 0.11246274 0.10067128\n",
      "  0.09756664 0.10094839 0.10792946 0.08676241]\n",
      " [0.10958269 0.09376193 0.09340443 0.10830342 0.11909852 0.09334894\n",
      "  0.08716951 0.10118631 0.09964963 0.0944946 ]\n",
      " [0.10620819 0.08781832 0.09454186 0.1130541  0.10445075 0.09789303\n",
      "  0.09875409 0.09746889 0.09858199 0.10122889]\n",
      " [0.11434099 0.08415142 0.10660606 0.0917445  0.134844   0.09260892\n",
      "  0.08406638 0.10420121 0.09647338 0.09096298]\n",
      " [0.11695843 0.09505361 0.08945684 0.11074061 0.11334838 0.09100918\n",
      "  0.08978739 0.102367   0.09654505 0.09473341]\n",
      " [0.10631578 0.09168931 0.10220659 0.09773097 0.11855384 0.08540566\n",
      "  0.09511745 0.11203559 0.09018222 0.10076261]\n",
      " [0.10441003 0.09656459 0.100405   0.0985523  0.11236613 0.0928556\n",
      "  0.09158776 0.10155267 0.11023182 0.09147408]\n",
      " [0.11285044 0.09104579 0.07811502 0.08890031 0.11139228 0.09432893\n",
      "  0.09696001 0.10339292 0.12418942 0.09882496]\n",
      " [0.10387142 0.09032033 0.103182   0.09298836 0.10948366 0.09582881\n",
      "  0.10319474 0.1012559  0.10166845 0.09820637]\n",
      " [0.10275081 0.10018881 0.08780257 0.07755588 0.13508509 0.09881443\n",
      "  0.10474311 0.09483132 0.10336254 0.09486534]\n",
      " [0.10524513 0.09295707 0.09759799 0.10494013 0.1017452  0.10276752\n",
      "  0.09294268 0.09990943 0.10999243 0.0919024 ]\n",
      " [0.09775327 0.09947117 0.09573565 0.11279833 0.1013307  0.0917502\n",
      "  0.09961286 0.10619699 0.09841967 0.09693109]\n",
      " [0.10912428 0.09870882 0.09728348 0.09792776 0.12634411 0.09234231\n",
      "  0.09649117 0.09636655 0.09017873 0.09523281]\n",
      " [0.09245432 0.08996885 0.09025554 0.08601744 0.13589123 0.11053067\n",
      "  0.10179639 0.09307466 0.10260429 0.09740652]\n",
      " [0.1201351  0.09353366 0.10020577 0.10023188 0.09867547 0.10735897\n",
      "  0.0801312  0.10018331 0.09560335 0.10394133]\n",
      " [0.11207651 0.10097166 0.09933092 0.09583317 0.09762542 0.09249412\n",
      "  0.09771957 0.09876947 0.10371759 0.10146163]\n",
      " [0.09524302 0.08158113 0.08663765 0.09333496 0.12842476 0.08984582\n",
      "  0.09486075 0.1175332  0.10667021 0.10586851]\n",
      " [0.10626725 0.08446591 0.09184045 0.09939165 0.11798699 0.09823394\n",
      "  0.08985862 0.10315417 0.10280909 0.10599198]\n",
      " [0.08847103 0.08929822 0.08683718 0.09073959 0.12306989 0.11195141\n",
      "  0.08708337 0.10190609 0.11345698 0.10718618]\n",
      " [0.10581863 0.10029663 0.10912874 0.09035183 0.10381128 0.11246856\n",
      "  0.07743559 0.1075     0.09853081 0.09465795]\n",
      " [0.12162804 0.08409124 0.10079971 0.09657677 0.11669122 0.0845084\n",
      "  0.0886865  0.1076361  0.10257629 0.09680581]\n",
      " [0.09725787 0.10450993 0.09849674 0.09633821 0.1113697  0.10631368\n",
      "  0.09241087 0.09234658 0.10255841 0.09839805]\n",
      " [0.11796758 0.08887488 0.10591557 0.10466184 0.10567469 0.09203155\n",
      "  0.08925217 0.08984519 0.09542217 0.11035436]\n",
      " [0.10917021 0.09495485 0.10024624 0.10045823 0.10643252 0.09604888\n",
      "  0.0970886  0.09568075 0.1033913  0.09652838]\n",
      " [0.10432275 0.09856747 0.08672604 0.0998487  0.11734352 0.08938241\n",
      "  0.08745965 0.10849503 0.10972605 0.09812848]\n",
      " [0.11000524 0.09079881 0.09658185 0.09982739 0.12658012 0.0821197\n",
      "  0.09821925 0.09447666 0.09935801 0.10203291]\n",
      " [0.101772   0.09965377 0.09742601 0.10446803 0.11244847 0.10235134\n",
      "  0.08984217 0.10699873 0.09997217 0.08506728]\n",
      " [0.09658137 0.09617296 0.11070977 0.10360953 0.11449821 0.09306548\n",
      "  0.09000213 0.10423677 0.09356906 0.09755474]\n",
      " [0.10776601 0.08912192 0.10848664 0.08820912 0.12533863 0.10126817\n",
      "  0.08976524 0.08899157 0.09803317 0.10301948]\n",
      " [0.10063798 0.09917966 0.10785211 0.09544443 0.10611922 0.09934577\n",
      "  0.08998509 0.10145053 0.10875422 0.091231  ]\n",
      " [0.12479682 0.08508889 0.09852931 0.09065844 0.11234341 0.10665279\n",
      "  0.09604868 0.093402   0.10369092 0.08878873]\n",
      " [0.10249028 0.10269578 0.08534376 0.10185789 0.10394815 0.09882604\n",
      "  0.09711799 0.10559568 0.10996787 0.09215661]\n",
      " [0.1205185  0.08385894 0.11414094 0.09851604 0.12075514 0.08520523\n",
      "  0.08931832 0.09749957 0.10012844 0.09005887]\n",
      " [0.10520411 0.09069867 0.0991246  0.09487692 0.11838517 0.10588536\n",
      "  0.09019391 0.09818433 0.10409545 0.09335151]\n",
      " [0.11579537 0.09079804 0.09642581 0.10221726 0.09967525 0.09847636\n",
      "  0.08960976 0.11020718 0.1032308  0.09356422]\n",
      " [0.10129044 0.08397598 0.09692943 0.09735198 0.12381012 0.08125434\n",
      "  0.09119253 0.10593916 0.11044341 0.10781257]\n",
      " [0.10046867 0.08150185 0.10555252 0.09907381 0.11367971 0.09159431\n",
      "  0.09597009 0.09120117 0.11090608 0.11005175]\n",
      " [0.08851966 0.08975526 0.09942041 0.09771643 0.12842952 0.09491504\n",
      "  0.09164505 0.10030837 0.11422466 0.09506565]\n",
      " [0.09916436 0.09097359 0.09548494 0.1154781  0.11452072 0.08606592\n",
      "  0.09324214 0.10340601 0.10836166 0.09330262]\n",
      " [0.10679428 0.08869223 0.10906291 0.08589009 0.13878588 0.09173302\n",
      "  0.08614849 0.1046444  0.08969656 0.09855213]\n",
      " [0.10423171 0.0882032  0.08832271 0.09596223 0.12500589 0.09576251\n",
      "  0.09875464 0.09789163 0.10689578 0.09896969]\n",
      " [0.09883373 0.09721024 0.08927647 0.10475742 0.10515393 0.09946837\n",
      "  0.09557138 0.10785434 0.10106691 0.10080718]\n",
      " [0.10093851 0.08930863 0.09403308 0.10159816 0.1120787  0.08720435\n",
      "  0.09263307 0.10653801 0.11273333 0.1029342 ]\n",
      " [0.11301236 0.09229641 0.09834347 0.10670844 0.09907933 0.08877367\n",
      "  0.10401641 0.09815537 0.10092485 0.09868976]\n",
      " [0.10976389 0.09928427 0.0960654  0.10696045 0.11095618 0.09500159\n",
      "  0.09386488 0.09955537 0.09833193 0.09021613]\n",
      " [0.10138083 0.09444512 0.1066385  0.09153752 0.11114748 0.10292725\n",
      "  0.09517007 0.09974612 0.10185315 0.09515395]\n",
      " [0.11081794 0.09710759 0.10389887 0.09178407 0.11953229 0.10138084\n",
      "  0.08548637 0.09046839 0.09383441 0.10568921]\n",
      " [0.10670548 0.09494876 0.09337129 0.09717076 0.11445783 0.09151976\n",
      "  0.08081356 0.10248979 0.11198381 0.10653897]\n",
      " [0.1041381  0.08555545 0.08973054 0.11363329 0.11711039 0.10003681\n",
      "  0.08757137 0.09637827 0.11598604 0.08985976]\n",
      " [0.1104373  0.09223922 0.1048684  0.09721992 0.10830649 0.10100708\n",
      "  0.09356464 0.09244049 0.10654622 0.09337022]\n",
      " [0.10195037 0.08473759 0.10001659 0.09875679 0.12434012 0.10314917\n",
      "  0.10053752 0.08328103 0.09995595 0.10327495]\n",
      " [0.10348023 0.10369237 0.09977177 0.09757773 0.10769872 0.10103324\n",
      "  0.09329019 0.09809595 0.092881   0.10247878]\n",
      " [0.12336665 0.09275644 0.10235985 0.10753643 0.10650449 0.08891625\n",
      "  0.08501786 0.09288699 0.09820639 0.10244854]\n",
      " [0.10153744 0.09007008 0.10585173 0.09993878 0.13167015 0.08814597\n",
      "  0.09318393 0.1029685  0.09936794 0.08726538]\n",
      " [0.10048537 0.10013952 0.09687581 0.09012081 0.11564428 0.09476211\n",
      "  0.09568794 0.09635609 0.10208303 0.10784506]\n",
      " [0.10159245 0.09042999 0.08037577 0.07473478 0.13063604 0.11103364\n",
      "  0.09775881 0.10402836 0.10261048 0.10679965]\n",
      " [0.10557817 0.09022874 0.09447343 0.08463857 0.11787967 0.10705428\n",
      "  0.09140218 0.09676097 0.11858079 0.09340323]\n",
      " [0.10886705 0.09007243 0.11389049 0.09782992 0.1081415  0.09364463\n",
      "  0.08769238 0.09599377 0.09923155 0.10463627]\n",
      " [0.11609894 0.0916328  0.09701064 0.1004007  0.11192793 0.09106143\n",
      "  0.08835964 0.10610899 0.10269964 0.09469929]\n",
      " [0.10158957 0.10152687 0.09798071 0.09048623 0.10891959 0.08796106\n",
      "  0.10099974 0.10445823 0.1002891  0.10578885]\n",
      " [0.10546586 0.09644926 0.10608421 0.09752837 0.10004315 0.09971746\n",
      "  0.09750178 0.09877265 0.10685261 0.09158469]\n",
      " [0.11335874 0.08538521 0.08322135 0.09154259 0.12299655 0.0925713\n",
      "  0.08620073 0.10363591 0.12145349 0.09963415]\n",
      " [0.10328389 0.08210048 0.10608489 0.09666917 0.10892255 0.09047387\n",
      "  0.10261367 0.09612306 0.11318178 0.10054664]\n",
      " [0.10552864 0.09338173 0.10132465 0.09800684 0.10535304 0.1113069\n",
      "  0.09134963 0.09796902 0.10075433 0.0950252 ]\n",
      " [0.10731903 0.09222992 0.10210102 0.08725426 0.10863984 0.09608518\n",
      "  0.09484219 0.09751064 0.107524   0.10649391]\n",
      " [0.09525764 0.0874076  0.09210413 0.08860993 0.1062915  0.10179854\n",
      "  0.10285529 0.11751647 0.11489917 0.09325969]\n",
      " [0.10012245 0.10203651 0.10123184 0.09793521 0.1036573  0.0969409\n",
      "  0.09594471 0.0987118  0.10244785 0.10097139]\n",
      " [0.10144881 0.09568273 0.10824303 0.09283815 0.11369109 0.08960103\n",
      "  0.09838109 0.09698396 0.10918148 0.09394857]\n",
      " [0.09642214 0.0885693  0.09742217 0.10002788 0.10725357 0.09598017\n",
      "  0.10229896 0.09717285 0.10563431 0.10921862]\n",
      " [0.10278021 0.0804127  0.09823243 0.09891471 0.11245684 0.09826967\n",
      "  0.08896939 0.10224548 0.12397864 0.09373988]\n",
      " [0.11932819 0.08235739 0.08817866 0.09334993 0.115991   0.09393818\n",
      "  0.09584143 0.10086986 0.10567416 0.10447115]\n",
      " [0.10478517 0.08885484 0.09306289 0.10009955 0.11002306 0.09230997\n",
      "  0.09719002 0.09831656 0.11070257 0.10465542]\n",
      " [0.12066499 0.08863665 0.09713372 0.10989219 0.09880439 0.09282687\n",
      "  0.08827912 0.10310438 0.10357481 0.09708289]\n",
      " [0.10702631 0.09580133 0.10852642 0.10607984 0.10353006 0.08498246\n",
      "  0.09436512 0.10183769 0.10654799 0.09130275]\n",
      " [0.12243488 0.09304187 0.10589343 0.09495958 0.13194923 0.08790719\n",
      "  0.0854933  0.08610687 0.0837649  0.10844876]\n",
      " [0.10387359 0.0886225  0.10313645 0.10515039 0.11003068 0.09223899\n",
      "  0.08846679 0.10517696 0.09891818 0.10438541]\n",
      " [0.1171812  0.09005783 0.08713283 0.08682606 0.11305323 0.09729461\n",
      "  0.09550114 0.09540948 0.10613604 0.11140761]\n",
      " [0.12552184 0.0848744  0.09699795 0.10229237 0.11550739 0.09144508\n",
      "  0.08411778 0.09626359 0.12176993 0.08120967]\n",
      " [0.11584084 0.08616224 0.10191874 0.09568633 0.112441   0.10176707\n",
      "  0.08936964 0.09506513 0.10599077 0.09575819]\n",
      " [0.10355595 0.09226959 0.09503595 0.09890129 0.11631671 0.0900443\n",
      "  0.09000579 0.09926035 0.11156152 0.10304851]\n",
      " [0.09345859 0.09305917 0.10058804 0.09738071 0.12240675 0.0948065\n",
      "  0.09594469 0.09645748 0.10538585 0.10051221]\n",
      " [0.10216236 0.07870773 0.1040002  0.09309993 0.14069746 0.08336335\n",
      "  0.09351892 0.09373321 0.10654927 0.10416758]\n",
      " [0.10272521 0.08478599 0.10479834 0.09078751 0.1102506  0.10888772\n",
      "  0.09566361 0.1051624  0.0955079  0.10143083]\n",
      " [0.09716218 0.09383881 0.09358241 0.10593748 0.11451206 0.09812226\n",
      "  0.09595473 0.09597934 0.10355502 0.10135565]\n",
      " [0.09929024 0.09515039 0.10360604 0.10701346 0.10761721 0.08765777\n",
      "  0.09938011 0.09664292 0.10577296 0.09786884]\n",
      " [0.10510467 0.09041795 0.09861306 0.10477752 0.10583501 0.09351312\n",
      "  0.09798467 0.1002138  0.10334431 0.10019588]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3077974, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3077974.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3057115, step = 2\n",
      "INFO:tensorflow:global_step/sec: 2.98841\n",
      "INFO:tensorflow:loss = 2.282627, step = 102 (33.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92096\n",
      "INFO:tensorflow:loss = 2.2452447, step = 202 (34.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83969\n",
      "INFO:tensorflow:loss = 2.2206957, step = 302 (35.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88556\n",
      "INFO:tensorflow:loss = 2.2202332, step = 402 (34.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72341\n",
      "INFO:tensorflow:loss = 2.1683571, step = 502 (36.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87826\n",
      "INFO:tensorflow:loss = 2.1488724, step = 602 (34.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84429\n",
      "INFO:tensorflow:loss = 2.0718477, step = 702 (35.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08301\n",
      "INFO:tensorflow:loss = 2.0559278, step = 802 (32.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0914\n",
      "INFO:tensorflow:loss = 1.8564177, step = 902 (32.344 sec)\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "mnist_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
